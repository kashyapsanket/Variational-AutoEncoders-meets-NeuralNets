{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VAE and FFNN comparison",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kashyapsanket/Variational-AutoEncoders-meets-NeuralNets/blob/master/VAE_and_FFNN_comparison.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "-b4mz5qNsacx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "```\n",
        "\n",
        "#  Variational Autoencoders meet MNIST\n",
        "\n",
        "---\n",
        "\n",
        "*Sanket Kashyap*"
      ]
    },
    {
      "metadata": {
        "id": "fEdXWDk9oxMb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras import layers\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Model, Sequential\n",
        "from keras.utils import to_categorical\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.layers import Dense\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EfAc3vxbstQq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Data Input and Partition**\n",
        "\n",
        "---\n",
        "The dataset being used here is the MNIST Handwritten digits dataset present in the keras library. The images are 28*28 black and white images with classes labelled from 0-9.\n",
        "\n",
        "The next cell reads the input data and partitions it into three sets -\n",
        "\n",
        "1.   X_70, Y_70 : Containing 70% of images of all classes\n",
        "2.   X_20, Y_20 : Containing 20% of images of all classes\n",
        "3. X_10, Y_10 : Containing 10% of images of all classes\n",
        "\n",
        "The data is reshaped and kept for the training of a simple feed-forward neural network\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "NSuBhKkYpTW4",
        "colab_type": "code",
        "outputId": "46971509-b15d-4fb7-d213-856765b73318",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
        "\n",
        "Y = list(Y_train) + list(Y_test)\n",
        "print(len(Y))\n",
        "\n",
        "X = np.vstack((X_train, X_test))\n",
        "print(len(X))\n",
        "\n",
        "data_dict = {}\n",
        "for i in range(len(Y)):\n",
        "  data_dict[Y[i]] = []\n",
        "\n",
        "for i in range(len(X)):\n",
        "  data_dict[Y[i]].append(X[i])\n",
        "\n",
        "X_70 = []\n",
        "X_20 = []\n",
        "X_10 = []\n",
        "\n",
        "Y_70 = []\n",
        "Y_20 = []\n",
        "Y_10 = []\n",
        "\n",
        "for key, value in data_dict.items():\n",
        "  x = value\n",
        "  y = [key]*len(value)\n",
        "  x_70, x_30, y_70, y_30 = train_test_split(x, y, test_size=0.3)\n",
        "  x_20, x_10, y_20, y_10 = train_test_split(x_30, y_30, test_size =0.34)\n",
        "  X_70 += x_70\n",
        "  Y_70 += y_70\n",
        "  X_20 += x_20\n",
        "  Y_20 += y_20\n",
        "  X_10 += x_10\n",
        "  Y_10 += y_10\n",
        "\n",
        "  \n",
        "X_70 = np.array(X_70)\n",
        "X_20 = np.array(X_20)\n",
        "X_10 = np.array(X_10)\n",
        "\n",
        "X_70 = X_70.astype('float32') / 255.\n",
        "X_70 = X_70.reshape(X_70.shape + (1,))\n",
        "\n",
        "X_20 = X_20.astype('float32') / 255.\n",
        "X_20 = X_20.reshape(X_20.shape + (1,))\n",
        "\n",
        "X_10 = X_10.astype('float32') / 255.\n",
        "X_10 = X_10.reshape(X_10.shape + (1,))\n",
        "\n",
        "Y_70_ohe = keras.utils.to_categorical(Y_70, 10)\n",
        "Y_20_ohe = keras.utils.to_categorical(Y_20, 10)\n",
        "Y_10_ohe = keras.utils.to_categorical(Y_10, 10)\n",
        "\n",
        "X_70_flat = X_70.reshape(48996,784)\n",
        "X_10_flat = X_10.reshape(7145,784)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "70000\n",
            "70000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bfmZNk1LpUPK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image_shape = (28, 28, 1)\n",
        "latent_dim = 10\n",
        "batch_size = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VFBj9z1mtzWp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Part - 1 : Building blocks  of the VAE** \n",
        "\n",
        "---\n",
        "\n",
        "The following cell creates all the required components of the VAE and the helper functions.\n",
        "\n",
        "*   Encoder\n",
        "*   Decoder\n",
        "*   Sampler\n",
        "*   Loss Function (as discussed in slides)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "X3ChnCPFrJi9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_encoder():\n",
        "    encoder_iput = layers.Input(shape=image_shape)\n",
        "    \n",
        "    x = layers.Conv2D(32, 3, padding='same', activation='relu')(encoder_iput)\n",
        "    x = layers.Conv2D(64, 3, padding='same', activation='relu', strides=(2, 2))(x)\n",
        "    x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
        "    x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(32, activation='relu')(x)\n",
        "\n",
        "    z_mean = layers.Dense(latent_dim)(x)\n",
        "    z_log_var = layers.Dense(latent_dim)(x)\n",
        "\n",
        "    return Model(encoder_iput, [z_mean, z_log_var], name='encoder')\n",
        "\n",
        "def create_decoder():\n",
        "    decoder_input = layers.Input(shape=(latent_dim,))\n",
        "    \n",
        "    x = layers.Dense(12544, activation='relu')(decoder_input)\n",
        "    x = layers.Reshape((14, 14, 64))(x)\n",
        "    x = layers.Conv2DTranspose(32, 3, padding='same', activation='relu', strides=(2, 2))(x)\n",
        "    x = layers.Conv2D(1, 3, padding='same', activation='sigmoid')(x)\n",
        "    \n",
        "    return Model(decoder_input, x, name='decoder')\n",
        "  \n",
        "def sample(args):\n",
        "    z_mean, z_log_var = args\n",
        "    z_sigma = K.sqrt(K.exp(z_log_var))\n",
        "    epsilon = K.random_normal(shape=K.shape(z_mean), mean=0., stddev=1.)\n",
        "    return z_mean + z_sigma * epsilon\n",
        "\n",
        "def create_sampler():\n",
        "    return layers.Lambda(sample, name='sampler')\n",
        "\n",
        "def neg_variational_lower_bound(x, t_decoded):\n",
        "    # Reconstruction loss\n",
        "    rc_loss = K.sum(K.binary_crossentropy(\n",
        "        K.batch_flatten(x), \n",
        "        K.batch_flatten(t_decoded)), axis=-1)\n",
        "\n",
        "    # Regularization term (KL divergence)\n",
        "    kl_loss = -0.5 * K.sum(1 + z_log_sigma \\\n",
        "                             - K.square(z_mu) \\\n",
        "                             - K.exp(z_log_sigma), axis=-1)\n",
        "    \n",
        "    # Average over mini-batch\n",
        "    return K.mean(rc_loss + kl_loss)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QAD6-F-uub8y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The next cell merges all the constituents of the VAE to create an end to end model. We train this for 35 epochs to finish training our VAE."
      ]
    },
    {
      "metadata": {
        "id": "C_v0kza0rWP9",
        "colab_type": "code",
        "outputId": "a1054393-b60f-4a6c-c49a-4839278b3799",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1295
        }
      },
      "cell_type": "code",
      "source": [
        "enc = create_encoder()\n",
        "dec = create_decoder()\n",
        "sampler = create_sampler()\n",
        "\n",
        "x = layers.Input(shape=image_shape)\n",
        "z_mu, z_log_sigma = enc(x)\n",
        "z = sampler([z_mu, z_log_sigma])\n",
        "z_decoded = dec(z)\n",
        "\n",
        "vae = Model(x, z_decoded, name='vae')\n",
        "\n",
        "vae.compile(optimizer='rmsprop', loss=neg_variational_lower_bound)\n",
        "vae.fit(x=X_70, \n",
        "         y=X_70,\n",
        "         epochs=35,\n",
        "         shuffle=True,\n",
        "         batch_size=batch_size,\n",
        "         verbose=2)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/35\n",
            " - 12s - loss: 957.2691\n",
            "Epoch 2/35\n",
            " - 11s - loss: 145.0232\n",
            "Epoch 3/35\n",
            " - 11s - loss: 134.5560\n",
            "Epoch 4/35\n",
            " - 11s - loss: 127.3346\n",
            "Epoch 5/35\n",
            " - 11s - loss: 122.8461\n",
            "Epoch 6/35\n",
            " - 11s - loss: 119.1327\n",
            "Epoch 7/35\n",
            " - 11s - loss: 115.8267\n",
            "Epoch 8/35\n",
            " - 11s - loss: 113.6010\n",
            "Epoch 9/35\n",
            " - 11s - loss: 112.0785\n",
            "Epoch 10/35\n",
            " - 11s - loss: 110.9181\n",
            "Epoch 11/35\n",
            " - 11s - loss: 109.9425\n",
            "Epoch 12/35\n",
            " - 11s - loss: 109.1430\n",
            "Epoch 13/35\n",
            " - 11s - loss: 108.4722\n",
            "Epoch 14/35\n",
            " - 11s - loss: 107.8045\n",
            "Epoch 15/35\n",
            " - 11s - loss: 107.3070\n",
            "Epoch 16/35\n",
            " - 11s - loss: 106.7499\n",
            "Epoch 17/35\n",
            " - 11s - loss: 106.2563\n",
            "Epoch 18/35\n",
            " - 11s - loss: 105.9177\n",
            "Epoch 19/35\n",
            " - 11s - loss: 105.4952\n",
            "Epoch 20/35\n",
            " - 11s - loss: 105.1228\n",
            "Epoch 21/35\n",
            " - 11s - loss: 104.8265\n",
            "Epoch 22/35\n",
            " - 11s - loss: 104.4963\n",
            "Epoch 23/35\n",
            " - 11s - loss: 104.2160\n",
            "Epoch 24/35\n",
            " - 11s - loss: 103.9358\n",
            "Epoch 25/35\n",
            " - 11s - loss: 103.7139\n",
            "Epoch 26/35\n",
            " - 11s - loss: 103.4659\n",
            "Epoch 27/35\n",
            " - 11s - loss: 103.2755\n",
            "Epoch 28/35\n",
            " - 11s - loss: 103.0636\n",
            "Epoch 29/35\n",
            " - 11s - loss: 102.8418\n",
            "Epoch 30/35\n",
            " - 11s - loss: 102.6825\n",
            "Epoch 31/35\n",
            " - 11s - loss: 102.4736\n",
            "Epoch 32/35\n",
            " - 11s - loss: 102.3187\n",
            "Epoch 33/35\n",
            " - 11s - loss: 102.1796\n",
            "Epoch 34/35\n",
            " - 11s - loss: 102.0382\n",
            "Epoch 35/35\n",
            " - 11s - loss: 101.9116\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc2e0e63630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "ujultIz-v0jH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Part 2 : **\n",
        "We first obtain the predictions of the encoder and use them to train an FFNN with the number of neurons in the hidden layer being the hyperparameter to be changed. The input of the neural network depends on the latent_dim described in an earlier cell"
      ]
    },
    {
      "metadata": {
        "id": "V26LSZmOupYL",
        "colab_type": "code",
        "outputId": "c292585b-1f2c-447f-b10e-fe9822759a8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "X_20_latent = enc.predict(X_20)[0]\n",
        "X_10_latent = enc.predict(X_10)[0]\n",
        "\n",
        "X_20_latent = np.array(X_20_latent)\n",
        "X_10_latent = np.array(X_10_latent)\n",
        "\n",
        "print(X_20_latent.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(13859, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mj2G3fEcvAvl",
        "colab_type": "code",
        "outputId": "243a1b4f-8284-4111-9bf0-6b6926287be0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2033
        }
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(200, activation='relu', input_shape=(latent_dim,)))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_20_latent, Y_20_ohe,\n",
        "                    batch_size=256,\n",
        "                    epochs=50,\n",
        "                    verbose=1,\n",
        "                    validation_data=(X_10_latent, Y_10_ohe))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_31 (Dense)             (None, 200)               2200      \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 10)                2010      \n",
            "=================================================================\n",
            "Total params: 4,210\n",
            "Trainable params: 4,210\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 13859 samples, validate on 7145 samples\n",
            "Epoch 1/50\n",
            "13859/13859 [==============================] - 1s 81us/step - loss: 1.4527 - acc: 0.7378 - val_loss: 0.8589 - val_acc: 0.8728\n",
            "Epoch 2/50\n",
            "13859/13859 [==============================] - 0s 17us/step - loss: 0.5962 - acc: 0.8951 - val_loss: 0.4063 - val_acc: 0.9129\n",
            "Epoch 3/50\n",
            "13859/13859 [==============================] - 0s 16us/step - loss: 0.3371 - acc: 0.9198 - val_loss: 0.2811 - val_acc: 0.9289\n",
            "Epoch 4/50\n",
            "13859/13859 [==============================] - 0s 16us/step - loss: 0.2572 - acc: 0.9302 - val_loss: 0.2369 - val_acc: 0.9348\n",
            "Epoch 5/50\n",
            "13859/13859 [==============================] - 0s 20us/step - loss: 0.2232 - acc: 0.9372 - val_loss: 0.2148 - val_acc: 0.9401\n",
            "Epoch 6/50\n",
            "13859/13859 [==============================] - 0s 19us/step - loss: 0.2035 - acc: 0.9427 - val_loss: 0.2014 - val_acc: 0.9428\n",
            "Epoch 7/50\n",
            "13859/13859 [==============================] - 0s 18us/step - loss: 0.1895 - acc: 0.9441 - val_loss: 0.1905 - val_acc: 0.9474\n",
            "Epoch 8/50\n",
            "13859/13859 [==============================] - 0s 20us/step - loss: 0.1781 - acc: 0.9465 - val_loss: 0.1827 - val_acc: 0.9493\n",
            "Epoch 9/50\n",
            "13859/13859 [==============================] - 0s 21us/step - loss: 0.1696 - acc: 0.9496 - val_loss: 0.1755 - val_acc: 0.9506\n",
            "Epoch 10/50\n",
            "13859/13859 [==============================] - 0s 18us/step - loss: 0.1617 - acc: 0.9518 - val_loss: 0.1711 - val_acc: 0.9528\n",
            "Epoch 11/50\n",
            "13859/13859 [==============================] - 0s 19us/step - loss: 0.1546 - acc: 0.9541 - val_loss: 0.1658 - val_acc: 0.9535\n",
            "Epoch 12/50\n",
            "13859/13859 [==============================] - 0s 18us/step - loss: 0.1489 - acc: 0.9566 - val_loss: 0.1608 - val_acc: 0.9520\n",
            "Epoch 13/50\n",
            "13859/13859 [==============================] - 0s 21us/step - loss: 0.1437 - acc: 0.9578 - val_loss: 0.1575 - val_acc: 0.9561\n",
            "Epoch 14/50\n",
            "13859/13859 [==============================] - 0s 19us/step - loss: 0.1386 - acc: 0.9600 - val_loss: 0.1535 - val_acc: 0.9562\n",
            "Epoch 15/50\n",
            "13859/13859 [==============================] - 0s 18us/step - loss: 0.1339 - acc: 0.9623 - val_loss: 0.1506 - val_acc: 0.9570\n",
            "Epoch 16/50\n",
            "13859/13859 [==============================] - 0s 18us/step - loss: 0.1301 - acc: 0.9633 - val_loss: 0.1472 - val_acc: 0.9587\n",
            "Epoch 17/50\n",
            "13859/13859 [==============================] - 0s 21us/step - loss: 0.1270 - acc: 0.9638 - val_loss: 0.1453 - val_acc: 0.9583\n",
            "Epoch 18/50\n",
            "13859/13859 [==============================] - 0s 19us/step - loss: 0.1239 - acc: 0.9636 - val_loss: 0.1429 - val_acc: 0.9589\n",
            "Epoch 19/50\n",
            "13859/13859 [==============================] - 0s 19us/step - loss: 0.1207 - acc: 0.9662 - val_loss: 0.1434 - val_acc: 0.9594\n",
            "Epoch 20/50\n",
            "13859/13859 [==============================] - 0s 19us/step - loss: 0.1185 - acc: 0.9652 - val_loss: 0.1397 - val_acc: 0.9594\n",
            "Epoch 21/50\n",
            "13859/13859 [==============================] - 0s 21us/step - loss: 0.1161 - acc: 0.9665 - val_loss: 0.1377 - val_acc: 0.9596\n",
            "Epoch 22/50\n",
            "13859/13859 [==============================] - 0s 19us/step - loss: 0.1141 - acc: 0.9675 - val_loss: 0.1374 - val_acc: 0.9601\n",
            "Epoch 23/50\n",
            "13859/13859 [==============================] - 0s 19us/step - loss: 0.1119 - acc: 0.9683 - val_loss: 0.1352 - val_acc: 0.9608\n",
            "Epoch 24/50\n",
            "13859/13859 [==============================] - 0s 18us/step - loss: 0.1096 - acc: 0.9683 - val_loss: 0.1343 - val_acc: 0.9608\n",
            "Epoch 25/50\n",
            "13859/13859 [==============================] - 0s 21us/step - loss: 0.1077 - acc: 0.9692 - val_loss: 0.1348 - val_acc: 0.9601\n",
            "Epoch 26/50\n",
            "13859/13859 [==============================] - 0s 20us/step - loss: 0.1062 - acc: 0.9697 - val_loss: 0.1333 - val_acc: 0.9607\n",
            "Epoch 27/50\n",
            "13859/13859 [==============================] - 0s 20us/step - loss: 0.1051 - acc: 0.9701 - val_loss: 0.1321 - val_acc: 0.9624\n",
            "Epoch 28/50\n",
            "13859/13859 [==============================] - 0s 20us/step - loss: 0.1035 - acc: 0.9702 - val_loss: 0.1309 - val_acc: 0.9622\n",
            "Epoch 29/50\n",
            "13859/13859 [==============================] - 0s 18us/step - loss: 0.1020 - acc: 0.9706 - val_loss: 0.1318 - val_acc: 0.9625\n",
            "Epoch 30/50\n",
            "13859/13859 [==============================] - 0s 19us/step - loss: 0.1009 - acc: 0.9714 - val_loss: 0.1298 - val_acc: 0.9625\n",
            "Epoch 31/50\n",
            "13859/13859 [==============================] - 0s 19us/step - loss: 0.0995 - acc: 0.9720 - val_loss: 0.1302 - val_acc: 0.9628\n",
            "Epoch 32/50\n",
            "13859/13859 [==============================] - 0s 20us/step - loss: 0.0985 - acc: 0.9721 - val_loss: 0.1292 - val_acc: 0.9625\n",
            "Epoch 33/50\n",
            "13859/13859 [==============================] - 0s 19us/step - loss: 0.0973 - acc: 0.9720 - val_loss: 0.1288 - val_acc: 0.9632\n",
            "Epoch 34/50\n",
            "13859/13859 [==============================] - 0s 19us/step - loss: 0.0963 - acc: 0.9723 - val_loss: 0.1302 - val_acc: 0.9622\n",
            "Epoch 35/50\n",
            "13859/13859 [==============================] - 0s 18us/step - loss: 0.0954 - acc: 0.9726 - val_loss: 0.1279 - val_acc: 0.9635\n",
            "Epoch 36/50\n",
            "13859/13859 [==============================] - 0s 20us/step - loss: 0.0945 - acc: 0.9726 - val_loss: 0.1299 - val_acc: 0.9629\n",
            "Epoch 37/50\n",
            "13859/13859 [==============================] - 0s 19us/step - loss: 0.0935 - acc: 0.9731 - val_loss: 0.1269 - val_acc: 0.9631\n",
            "Epoch 38/50\n",
            "13859/13859 [==============================] - 0s 18us/step - loss: 0.0926 - acc: 0.9735 - val_loss: 0.1278 - val_acc: 0.9639\n",
            "Epoch 39/50\n",
            "13859/13859 [==============================] - 0s 20us/step - loss: 0.0918 - acc: 0.9728 - val_loss: 0.1270 - val_acc: 0.9639\n",
            "Epoch 40/50\n",
            "13859/13859 [==============================] - 0s 20us/step - loss: 0.0913 - acc: 0.9740 - val_loss: 0.1276 - val_acc: 0.9638\n",
            "Epoch 41/50\n",
            "13859/13859 [==============================] - 0s 19us/step - loss: 0.0903 - acc: 0.9742 - val_loss: 0.1278 - val_acc: 0.9642\n",
            "Epoch 42/50\n",
            "13859/13859 [==============================] - 0s 20us/step - loss: 0.0897 - acc: 0.9742 - val_loss: 0.1266 - val_acc: 0.9643\n",
            "Epoch 43/50\n",
            "13859/13859 [==============================] - 0s 20us/step - loss: 0.0886 - acc: 0.9742 - val_loss: 0.1263 - val_acc: 0.9638\n",
            "Epoch 44/50\n",
            "13859/13859 [==============================] - 0s 21us/step - loss: 0.0879 - acc: 0.9745 - val_loss: 0.1280 - val_acc: 0.9633\n",
            "Epoch 45/50\n",
            "13859/13859 [==============================] - 0s 20us/step - loss: 0.0876 - acc: 0.9745 - val_loss: 0.1281 - val_acc: 0.9640\n",
            "Epoch 46/50\n",
            "13859/13859 [==============================] - 0s 20us/step - loss: 0.0868 - acc: 0.9755 - val_loss: 0.1258 - val_acc: 0.9647\n",
            "Epoch 47/50\n",
            "13859/13859 [==============================] - 0s 20us/step - loss: 0.0859 - acc: 0.9755 - val_loss: 0.1281 - val_acc: 0.9638\n",
            "Epoch 48/50\n",
            "13859/13859 [==============================] - 0s 21us/step - loss: 0.0856 - acc: 0.9750 - val_loss: 0.1272 - val_acc: 0.9646\n",
            "Epoch 49/50\n",
            "13859/13859 [==============================] - 0s 20us/step - loss: 0.0849 - acc: 0.9754 - val_loss: 0.1260 - val_acc: 0.9643\n",
            "Epoch 50/50\n",
            "13859/13859 [==============================] - 0s 20us/step - loss: 0.0845 - acc: 0.9760 - val_loss: 0.1256 - val_acc: 0.9649\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yld_6CP9wRrs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Part 3 ** We create a simple FFNN, train it on Partition 1 and test it on Partition 3. The hyperparameter to change here is the number of neirons in the hidden layer."
      ]
    },
    {
      "metadata": {
        "id": "5vpfoFd6vkgs",
        "colab_type": "code",
        "outputId": "bb79b1ff-abad-4d7c-9589-a25011de3955",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1313
        }
      },
      "cell_type": "code",
      "source": [
        "model2 = Sequential()\n",
        "model2.add(Dense(200, activation='relu', input_shape=(784,)))\n",
        "model2.add(Dense(10, activation='softmax'))\n",
        "model2.summary()\n",
        "\n",
        "model2.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model2.fit(X_70_flat, Y_70_ohe,\n",
        "                    batch_size=256,\n",
        "                    epochs=30,\n",
        "                    verbose=1,\n",
        "                    validation_data=(X_10_flat, Y_10_ohe))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_29 (Dense)             (None, 200)               157000    \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 10)                2010      \n",
            "=================================================================\n",
            "Total params: 159,010\n",
            "Trainable params: 159,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 48996 samples, validate on 7145 samples\n",
            "Epoch 1/30\n",
            "48996/48996 [==============================] - 2s 33us/step - loss: 0.3865 - acc: 0.8943 - val_loss: 0.2319 - val_acc: 0.9369\n",
            "Epoch 2/30\n",
            "48996/48996 [==============================] - 1s 20us/step - loss: 0.1863 - acc: 0.9460 - val_loss: 0.1693 - val_acc: 0.9541\n",
            "Epoch 3/30\n",
            "48996/48996 [==============================] - 1s 20us/step - loss: 0.1345 - acc: 0.9597 - val_loss: 0.1360 - val_acc: 0.9632\n",
            "Epoch 4/30\n",
            "48996/48996 [==============================] - 1s 21us/step - loss: 0.1037 - acc: 0.9699 - val_loss: 0.1190 - val_acc: 0.9667\n",
            "Epoch 5/30\n",
            "48996/48996 [==============================] - 1s 20us/step - loss: 0.0838 - acc: 0.9752 - val_loss: 0.1067 - val_acc: 0.9698\n",
            "Epoch 6/30\n",
            "48996/48996 [==============================] - 1s 20us/step - loss: 0.0682 - acc: 0.9793 - val_loss: 0.1010 - val_acc: 0.9705\n",
            "Epoch 7/30\n",
            "48996/48996 [==============================] - 1s 20us/step - loss: 0.0566 - acc: 0.9834 - val_loss: 0.0993 - val_acc: 0.9706\n",
            "Epoch 8/30\n",
            "48996/48996 [==============================] - 1s 20us/step - loss: 0.0473 - acc: 0.9861 - val_loss: 0.0936 - val_acc: 0.9734\n",
            "Epoch 9/30\n",
            "48996/48996 [==============================] - 1s 20us/step - loss: 0.0399 - acc: 0.9886 - val_loss: 0.0903 - val_acc: 0.9735\n",
            "Epoch 10/30\n",
            "48996/48996 [==============================] - 1s 20us/step - loss: 0.0336 - acc: 0.9909 - val_loss: 0.0871 - val_acc: 0.9762\n",
            "Epoch 11/30\n",
            "48996/48996 [==============================] - 1s 20us/step - loss: 0.0285 - acc: 0.9921 - val_loss: 0.0883 - val_acc: 0.9754\n",
            "Epoch 12/30\n",
            "48996/48996 [==============================] - 1s 20us/step - loss: 0.0239 - acc: 0.9939 - val_loss: 0.0855 - val_acc: 0.9772\n",
            "Epoch 13/30\n",
            "48996/48996 [==============================] - 1s 20us/step - loss: 0.0210 - acc: 0.9946 - val_loss: 0.0853 - val_acc: 0.9745\n",
            "Epoch 14/30\n",
            "48996/48996 [==============================] - 1s 20us/step - loss: 0.0174 - acc: 0.9963 - val_loss: 0.0873 - val_acc: 0.9752\n",
            "Epoch 15/30\n",
            "48996/48996 [==============================] - 1s 20us/step - loss: 0.0146 - acc: 0.9968 - val_loss: 0.0872 - val_acc: 0.9765\n",
            "Epoch 16/30\n",
            "48996/48996 [==============================] - 1s 20us/step - loss: 0.0122 - acc: 0.9977 - val_loss: 0.0892 - val_acc: 0.9770\n",
            "Epoch 17/30\n",
            "48996/48996 [==============================] - 1s 20us/step - loss: 0.0104 - acc: 0.9980 - val_loss: 0.0888 - val_acc: 0.9756\n",
            "Epoch 18/30\n",
            "48996/48996 [==============================] - 1s 20us/step - loss: 0.0088 - acc: 0.9983 - val_loss: 0.0909 - val_acc: 0.9759\n",
            "Epoch 19/30\n",
            "48996/48996 [==============================] - 1s 20us/step - loss: 0.0077 - acc: 0.9986 - val_loss: 0.0921 - val_acc: 0.9763\n",
            "Epoch 20/30\n",
            "48996/48996 [==============================] - 1s 20us/step - loss: 0.0061 - acc: 0.9990 - val_loss: 0.0958 - val_acc: 0.9756\n",
            "Epoch 21/30\n",
            "48996/48996 [==============================] - 1s 20us/step - loss: 0.0051 - acc: 0.9992 - val_loss: 0.0903 - val_acc: 0.9772\n",
            "Epoch 22/30\n",
            "48996/48996 [==============================] - 1s 20us/step - loss: 0.0043 - acc: 0.9993 - val_loss: 0.0999 - val_acc: 0.9754\n",
            "Epoch 23/30\n",
            "48996/48996 [==============================] - 1s 20us/step - loss: 0.0037 - acc: 0.9994 - val_loss: 0.0933 - val_acc: 0.9769\n",
            "Epoch 24/30\n",
            "48996/48996 [==============================] - 1s 20us/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.1000 - val_acc: 0.9759\n",
            "Epoch 25/30\n",
            "48996/48996 [==============================] - 1s 20us/step - loss: 0.0024 - acc: 0.9997 - val_loss: 0.0980 - val_acc: 0.9765\n",
            "Epoch 26/30\n",
            "48996/48996 [==============================] - 1s 20us/step - loss: 0.0020 - acc: 0.9998 - val_loss: 0.1025 - val_acc: 0.9772\n",
            "Epoch 27/30\n",
            "48996/48996 [==============================] - 1s 20us/step - loss: 0.0018 - acc: 0.9998 - val_loss: 0.1028 - val_acc: 0.9772\n",
            "Epoch 28/30\n",
            "48996/48996 [==============================] - 1s 20us/step - loss: 0.0014 - acc: 0.9999 - val_loss: 0.1029 - val_acc: 0.9765\n",
            "Epoch 29/30\n",
            "48996/48996 [==============================] - 1s 20us/step - loss: 0.0011 - acc: 0.9999 - val_loss: 0.1043 - val_acc: 0.9776\n",
            "Epoch 30/30\n",
            "48996/48996 [==============================] - 1s 20us/step - loss: 0.0011 - acc: 0.9999 - val_loss: 0.1093 - val_acc: 0.9768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4-485Lib1Y43",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Part 4 : Comparison between methods used in Part 2 and Part 3**\n",
        "I used only single layer FFNNs for Part 3. I analysed results after changing the number of neurons in the hidden layer. For state of the art performance on the MNIST dataset, deep CNNs can be used which results in accuracies of upwards of 99.5%.\n",
        "\n",
        "\n",
        "*   20 neurons (15,910 parameters) - 95.3% accuracy\n",
        "*   100 neurons (79,510 paramters) - 97.4% accuracy\n",
        "*   200 neurons (159,610 paramters) - 97.7% accuracy\n",
        "\n",
        "For the VAE I tried three different latent_dimensions, \n",
        "\n",
        "*   2 dimensions, 100 neurons, ~1000 parameters - 75.2% accuracy \n",
        "*   8 dimensions, 100 neurons, ~2000 paramters - 95.6% accuracy \n",
        "*   8 dimensions, 200 neurons, ~4000 paramters - 96.2% accuracy \n",
        "*   16 dimensions, 400 neurons, ~10000 paramters - 93.95% accuracy\n",
        "*   16 dimensions, 100 neurons, ~2000 paramters - 95.2% accuracy \n",
        "*   10 dimensions, 1000 neurons, ~21000 paramters - 97.2% accuracy \n",
        "*   10 dimensions, 200 neurons, ~2000 paramters - 96.9% accuracy \n",
        "\n",
        "\n",
        "\n",
        "The major reason I feel that the FFNNs tend to perform  better is that the Gaussian distribution is not strong enough to capture the complete complexity of the MNIST dataset after a certain point and the performance peaks at ~97% accuracy, using a Gaussian prior with more diverse image datasets (eg. ImageNet, MS COCO) will lead to worse reconstructions\n",
        "\n",
        "The method of training in Part 2, is an incredibly useful one in case we have a shortage of labelled data. Deep CNNs and other deep networks require a lot of data to perform well without overfitting, with the VAE training method we can use the unlabelled data to train a VAE and use the encoder networks to further process the labelled data and train it with labels on a simpler neural network to achieve good results. This form of learning is known as semi-supervised learning.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "0gQyhwjovLUC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}